# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1WDZj5n1LDizHNuJgbEI6gRcYoU_dLjAn
"""

# Install necessary libraries
!pip install tensorflow kaggle

# Import libraries
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

# Setup Kaggle API
from google.colab import files
files.upload()  # Upload kaggle.json for Kaggle API

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/

# Download dataset from Kaggle
!kaggle datasets download -d jonathanoheix/face-expression-recognition-dataset
!unzip face-expression-recognition-dataset.zip

# Define paths
train_dir = 'images/train/'
validate_dir = 'images/validation/'  # Assuming test is used for validation

# Image data generator
train_datagen = ImageDataGenerator(
    rescale=1./255,
    validation_split=0.2
)

train_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(48, 48),  # Adjust size according to dataset
    batch_size=32,
    color_mode='grayscale',  # Adjust based on dataset; grayscale for this dataset
    class_mode='categorical',
    subset='training'
)

validation_generator = train_datagen.flow_from_directory(
    train_dir,
    target_size=(48, 48),  # Adjust size according to dataset
    batch_size=32,
    color_mode='grayscale',  # Adjust based on dataset; grayscale for this dataset
    class_mode='categorical',
    subset='validation'
)

# Define the CNN model
model = tf.keras.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(48, 48, 1)),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D((2, 2)),
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(7, activation='softmax')  # 7 emotion classes
])

# Compile the model
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(
    train_generator,
    steps_per_epoch=train_generator.samples // train_generator.batch_size,
    epochs=50,
    validation_data=validation_generator,
    validation_steps=validation_generator.samples // validation_generator.batch_size
)

# Evaluate the model
loss, accuracy = model.evaluate(validation_generator)
print(f"Validation loss: {loss}")
print(f"Validation accuracy: {accuracy}")

import matplotlib.pyplot as plt

# Plot training & validation accuracy values
plt.figure(figsize=(12, 6))
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import numpy as np

# Predict the classes for validation data
validation_generator.reset()
predictions = model.predict(validation_generator)
predicted_classes = np.argmax(predictions, axis=1)

# Get true classes from validation generator
true_classes = validation_generator.classes

# Compute confusion matrix
conf_matrix = confusion_matrix(true_classes, predicted_classes)

# Print classification report
class_names = list(validation_generator.class_indices.keys())
print("Classification Report:\n")
print(classification_report(true_classes, predicted_classes, target_names=class_names))

# Plot confusion matrix
plt.figure(figsize=(10, 7))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_names,
            yticklabels=class_names)
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix')
plt.show()

from sklearn.metrics import confusion_matrix
import numpy as np

# Predict the classes for validation data
validation_generator.reset()
predictions = model.predict(validation_generator)
predicted_classes = np.argmax(predictions, axis=1)

# Get true classes from validation generator
true_classes = validation_generator.classes

# Compute confusion matrix
conf_matrix = confusion_matrix(true_classes, predicted_classes)

# Calculate accuracy for each emotion class
class_names = list(validation_generator.class_indices.keys())
accuracy_per_class = {}

for i, class_name in enumerate(class_names):
    true_positive = conf_matrix[i, i]
    total = np.sum(conf_matrix[i, :])
    accuracy = (true_positive / total) * 100
    accuracy_per_class[class_name] = accuracy

# Print accuracy for each emotion
print("Accuracy for each emotion class:")
for class_name, accuracy in accuracy_per_class.items():
    print(f"{class_name}: {accuracy:.2f}%")

from sklearn.metrics import accuracy_score

# Predict the classes for validation data
validation_generator.reset()
predictions = model.predict(validation_generator)
predicted_classes = np.argmax(predictions, axis=1)

# Get true classes from validation generator
true_classes = validation_generator.classes

# Compute overall accuracy
overall_accuracy = accuracy_score(true_classes, predicted_classes) * 100
overall_accuracy1 = accuracy_score(true_classes, predicted_classes)
print(f"Overall Accuracy: {overall_accuracy1}%")

# Print overall accuracy
print(f"Overall Accuracy: {overall_accuracy:.2f}%")

model.save('emotion_detection_model.h5')